# -*- coding: utf-8 -*-
"""Multivariant_final_AirPollution.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15tQhIlL_yY8w4-y3m6WMyWrqAnt-eUuN
"""

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import  LabelEncoder,OneHotEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM,Dense,Dropout
from sklearn.metrics import mean_squared_error
from sklearn.compose import ColumnTransformer
import seaborn as sns

np.random.seed(7)

from google.colab import drive
drive.mount('/content/gdrive')

!ls "/content/gdrive/My Drive/ML_DataSet/AirPolution_Beijing.csv"

dataset=pd.read_csv('/content/gdrive/My Drive/ML_DataSet/AirPolution_Beijing.csv')
dataset.head()

dataset.dtypes

dataset['date']=pd.to_datetime(dataset[['year','month','day','hour']],format="%y%m%d%h")
dataset['date'].head()

#df=dataset.copy()
#df=df.iloc[24:,:]
#df['pm2.5']=df['pm2.5'].fillna(df['pm2.5'].mean())
#plt.plot(df.iloc[:24*7,5:6])
#plt.title('Plot of 1st one week Pollution day(2-1-2010 to 8-1-2010) of  Data Set')
#plt.xlabel('Time')
#plt.ylabel('Pollution')
#plt.show()

#print(dataset.dtypes)
dataset.drop(['No','year','month','day','hour'],axis=1,inplace=True)

dataset=dataset.set_index('date')
dataset.columns = ['pollution', 'dew', 'temp', 'press', 'wnd_dir', 'wnd_spd', 'snow', 'rain']
dataset.head()

dataset.shape

dataset=dataset.iloc[24:,:]
dataset.head()

dataset.shape

dataset.describe()

dataset.info()

#check if any NaN Value present or Not
print(dataset.isnull().any())
dataset.isnull().sum()

#fill the NaN value with the mean
dataset['pollution']=dataset['pollution'].fillna(dataset['pollution'].mean())

#check if any NaN Value present or Not
print(dataset.isnull().any())
dataset.isnull().sum()

#plot the whole dataset the Pollution Column
plt.plot(dataset.iloc[:,0:1])
plt.xlabel('Time')
plt.ylabel('Pollution')
plt.title('Pollution vs Time')
plt.show()

plt.plot(dataset.iloc[:24*7,0:1])
plt.title('Plot of 1st one week Pollution day(2-1-2010 to 8-1-2010) of  Data Set')
plt.xlabel('Time')
plt.ylabel('Pollution')
plt.show()

#check How many cataegory present in wnd_dir collumn
sns.countplot(x="wnd_dir",data=dataset)
plt.show()

# encoded the categorical value
encoder=LabelEncoder()
dataset.iloc[:,4]=encoder.fit_transform(dataset.iloc[:,4])
print(type(dataset))
dataset.head()

#perform corelation matrix
corrMatrix=dataset.corr()
sns.heatmap(corrMatrix, annot=True)
plt.show()

dataset=dataset.astype('float32')

# Take only pollution , dew, wnd_dir,wnd_spd collumn
#Drop the other collumn , As those collumn are no corelation with the pollution collumn 
dataset=dataset.iloc[:,[0,1,4,5]]
dataset.head()

#perform OneHotEncoding for dummy variable
df=dataset.copy()
transformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [2])],remainder='passthrough')
df = np.array(transformer.fit_transform(df), dtype=np.float)
print(df.shape)
#avoiding dummy variable trap
df=df[:,1:]
df.shape

df[:2,:]

#perform Normalization
sc=MinMaxScaler(feature_range=(0,1))
data_set_scaled=sc.fit_transform(df)
type(data_set_scaled)

#Divided whole dataset into train and test
# 1st 4th year data for training 
#last year data for testing
x=len(dataset)-365*24
train_scaled=data_set_scaled[:x,:]
test_scaled=data_set_scaled[x:,3:4]

print(train_scaled)
(test_scaled.shape)

#funcition for converting our own Sequence dataset for training
#I take previous 24 hour data for dependent variable and next 1 hour data  for Independent variable
# t-24 to t hour data for X_train and t+1 hour data for y_train


def Series_to_Supervised(train_scaled):
    X_train=[]
    y_train=[]
    for i in range(24,len(train_scaled)):
        X_train.append(train_scaled[i-24:i,:])
        y_train.append(train_scaled[i,3:4])
    return X_train,y_train

#function calling
X_train,y_train=Series_to_Supervised(train_scaled)
type(X_train)

#function for testing 
def Series_to_Supervised_for_Testing(data_set_scaled):
  X_test_check=data_set_scaled[len(train_scaled)-24:,:]
  X_test=[]
  for i in range(24,len(X_test_check)):
    X_test.append(X_test_check[i-24:i,:])
  return X_test

#function calling
X_test=Series_to_Supervised_for_Testing(data_set_scaled)
type(X_test)

#converting list to array
X_train,y_train=np.array(X_train),np.array(y_train)
X_test=np.array(X_test)

print('X_Traing Shape',X_train.shape)
print('Y_Traing Shape',y_train.shape)
print('X_Testing Shape',X_test.shape)
print('Y_Testing Shape',test_scaled.shape)

#Initialize the RNN model
regressor = Sequential()

#1st LSTM layer with Dropout Regulaziation
regressor.add(LSTM(units=100,return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))
regressor.add(Dropout(0.3))

#2nd  LSTM layer 
regressor.add(LSTM(units = 75,return_sequences = True))
regressor.add(Dropout(0.25))

#3rd  LSTM layer 
regressor.add(LSTM(units = 50, return_sequences = False))
regressor.add(Dropout(0.2))

#Output Layer
regressor.add(Dense(units = 1))

#Compile the model 
regressor.compile(optimizer = 'RMSProp', loss = 'mean_squared_error')

#fit the model
history=regressor.fit(X_train, y_train, epochs = 100, batch_size = 72,validation_data=(X_test,test_scaled))

regressor.summary()

#plot history
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='test')
plt.legend()
plt.show()

#Predict for the test value
y_pred=regressor.predict(X_test)
y_pred

#inverse transform for actual range
sc=MinMaxScaler(feature_range=(0,1))
data_set_scaled=sc.fit_transform(dataset.iloc[:,0:1].values)
y_pred=sc.inverse_transform(y_pred)
y_real=sc.inverse_transform(test_scaled)

print(y_pred)
y_real

#RMSE for TEsting Dataset
RMSE=np.sqrt(mean_squared_error(y_real,y_pred))
print('RMSE value of Testing',RMSE)

#Test Set plot
plt.plot(y_real,label='Real Value')
plt.plot(y_pred,label='Predict Value')
plt.title('Test Set')
plt.xlabel('Time')
plt.ylabel('Pollution')
plt.legend()
plt.show()

#Traing Set
X_pred=regressor.predict(X_train)
X_pred=sc.inverse_transform(X_pred)
#X_real=y_train.reshape(-1,1)
X_real=sc.inverse_transform(y_train)
#X_real.reshape(-1,1)
RMSE_train=np.sqrt(mean_squared_error(X_real,X_pred))
print('RMSE value for Traing Set',RMSE_train)

#Traing Set plot
plt.plot(X_real,label='Real Value')
plt.plot(X_pred,label='Predict Value')
plt.title('Training Set')
plt.xlabel('Time')
plt.ylabel('Pollution')
plt.legend()
plt.show()

plt.plot(y_real[:24*7,0],label='Actual Value ')
plt.plot(y_pred[:24*7,0],label='Predicted Value')
plt.title('Plot of 1st one week Pollution (1-1-2014 to 7-1-2014) of Testing Data Set')
plt.xlabel('Time')
plt.ylabel('Pollution')
plt.legend()
plt.show()

plt.scatter(x=dataset.index[len(dataset)-365*24:len(train_scaled)+24*7],y=dataset['pollution'].iloc[len(dataset)-365*24:len(train_scaled)+24*7],color='red',label='Actual Value')
plt.plot(dataset.index[len(dataset)-365*24:len(train_scaled)+24*7],y_pred[:24*7,0],label='Predicted Value')
plt.title('Plot of 1st one week Pollution day(1-1-2014 to 4-1-2014) of Testing Data Set')
plt.xlabel('Time')
plt.ylabel('Pollution')
plt.legend()
plt.show()

